import os
import dotenv
from langchain_community.vectorstores import FAISS
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from ocr import tool_ocr
from typing import List, Dict, Any, Optional
import logging

dotenv.load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

INDEX_PATH = "/home/gacoelho/Documents/agente_emisssao_documento/doc"

class DocumentProcessor:
    """Classe para processar e gerenciar documentos com desambiguaÃ§Ã£o inteligente"""
    
    def __init__(self):
        self.embeddings = AzureOpenAIEmbeddings(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            model=os.getenv("EMBEDDINGS_MODEL_NAME", "text-embedding-ada-002")
        )
        
        self.llm = AzureChatOpenAI(
            api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            temperature=0.3
        )
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
    
    def extrair_documentos_por_ocr(self, pasta_docs: str) -> List[Document]:
        """Extrai texto de documentos na pasta via OCR e retorna lista de Documentos"""
        documentos = []
        
        if not os.path.exists(pasta_docs):
            logger.warning(f"Pasta {pasta_docs} nÃ£o encontrada")
            return documentos
        
        # Verificar se hÃ¡ documentos processÃ¡veis
        arquivos_processaveis = []
        for arquivo in os.listdir(pasta_docs):
            caminho = os.path.join(pasta_docs, arquivo)
            if os.path.isfile(caminho) and arquivo.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg', '.tiff')):
                arquivos_processaveis.append(arquivo)
        
        if not arquivos_processaveis:
            logger.warning(f"Nenhum arquivo processÃ¡vel encontrado em {pasta_docs}")
            return documentos
        
        logger.info(f"Processando {len(arquivos_processaveis)} arquivos...")
        
        for arquivo in arquivos_processaveis:
            caminho = os.path.join(pasta_docs, arquivo)
            try:
                logger.info(f"Processando arquivo: {arquivo}")
                resultado = tool_ocr(caminho)
                texto = resultado.get("texto_extraido", "").strip()
                
                if texto:
                    # Dividir o texto em chunks menores
                    chunks = self.text_splitter.split_text(texto)
                    
                    for i, chunk in enumerate(chunks):
                        doc = Document(
                            page_content=chunk,
                            metadata={
                                "arquivo": arquivo,
                                "chunk_id": i,
                                "num_paginas": resultado.get("num_paginas", 0),
                                "tipo_arquivo": arquivo.split('.')[-1].lower(),
                                "tamanho_chunk": len(chunk)
                            }
                        )
                        documentos.append(doc)
                    
                    logger.info(f"Arquivo {arquivo} processado: {len(chunks)} chunks criados")
                else:
                    logger.warning(f"Nenhum texto extraÃ­do do arquivo {arquivo}")
                    
            except Exception as e:
                logger.error(f"Erro ao processar arquivo {arquivo}: {str(e)}")
        
        return documentos
    
    def criar_indice_faiss(self) -> bool:
        """Cria Ã­ndice FAISS a partir dos documentos extraÃ­dos via OCR"""
        logger.info("Criando Ã­ndice FAISS via OCR dos documentos na pasta...")
        
        try:
            docs = self.extrair_documentos_por_ocr(INDEX_PATH)
            
            if not docs:
                logger.warning("Nenhum documento extraÃ­do via OCR para criar Ã­ndice.")
                return False
            
            logger.info(f"{len(docs)} chunks de documentos processados")
            
            # Criar o Ã­ndice FAISS
            vectorstore = FAISS.from_documents(docs, self.embeddings)
            
            # Salvar o Ã­ndice
            os.makedirs(INDEX_PATH, exist_ok=True)
            vectorstore.save_local(INDEX_PATH)
            
            logger.info(f"Ãndice FAISS criado e salvo em {INDEX_PATH}")
            return True
            
        except Exception as e:
            logger.error(f"Erro ao criar Ã­ndice FAISS: {str(e)}")
            return False
    
    def carregar_indice(self) -> Optional[FAISS]:
        """Carrega o Ã­ndice FAISS existente ou cria um novo se necessÃ¡rio"""
        try:
            index_faiss = os.path.join(INDEX_PATH, "index.faiss")
            index_pkl = os.path.join(INDEX_PATH, "index.pkl")
            
            if not (os.path.exists(index_faiss) and os.path.exists(index_pkl)):
                logger.info("Ãndice nÃ£o encontrado, criando novo...")
                if not self.criar_indice_faiss():
                    return None
            
            vectorstore = FAISS.load_local(
                INDEX_PATH,
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            
            logger.info("Ãndice FAISS carregado com sucesso")
            return vectorstore
            
        except Exception as e:
            logger.error(f"Erro ao carregar Ã­ndice: {str(e)}")
            return None
    
    def escolher_documento_opcoes(self, opcoes: List[Document], pergunta: str) -> Document:
        """Permite ao usuÃ¡rio escolher entre mÃºltiplos documentos relevantes com contexto"""
        print(f"\nğŸ” Encontrei {len(opcoes)} documentos relevantes para: '{pergunta}'")
        print("=" * 80)
        
        for i, doc in enumerate(opcoes, 1):
            arquivo = doc.metadata.get("arquivo", "Desconhecido")
            chunk_id = doc.metadata.get("chunk_id", 0)
            tipo_arquivo = doc.metadata.get("tipo_arquivo", "desconhecido")
            tamanho = doc.metadata.get("tamanho_chunk", 0)
            
            # Mostrar contexto relevante
            resumo = doc.page_content[:200].replace("\n", " ").strip()
            
            print(f"{i}. ğŸ“„ {arquivo}")
            print(f"   ğŸ“ Chunk {chunk_id} | Tipo: {tipo_arquivo} | Tamanho: {tamanho} chars")
            print(f"   ğŸ“ {resumo}...")
            print()
        
        while True:
            try:
                escolha = input(f"ğŸ¯ Escolha um documento (1-{len(opcoes)}) ou 'auto' para seleÃ§Ã£o automÃ¡tica: ").strip()
                
                if escolha.lower() == 'auto':
                    # SeleÃ§Ã£o automÃ¡tica baseada na relevÃ¢ncia (primeiro resultado)
                    logger.info("SeleÃ§Ã£o automÃ¡tica ativada")
                    return opcoes[0]
                
                if escolha.isdigit() and 1 <= int(escolha) <= len(opcoes):
                    return opcoes[int(escolha) - 1]
                else:
                    print("âŒ OpÃ§Ã£o invÃ¡lida, tente novamente.")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ OperaÃ§Ã£o cancelada pelo usuÃ¡rio")
                return opcoes[0]  # Retorna a primeira opÃ§Ã£o como padrÃ£o
    
    def executar_rag(self, pergunta: str, max_results: int = 5, auto_clarify: bool = True) -> str:
        """Executa o pipeline RAG com Azure OpenAI e FAISS com desambiguaÃ§Ã£o inteligente"""
        try:
            # Carregar ou criar Ã­ndice
            vectorstore = self.carregar_indice()
            if not vectorstore:
                return "âŒ Erro: NÃ£o foi possÃ­vel carregar ou criar o Ã­ndice de documentos."
            
            # Configurar retriever sem score threshold para debug
            retriever = vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": max_results}
            )
            
            # Buscar documentos relevantes usando o mÃ©todo correto
            try:
                docs = retriever.invoke(pergunta)
            except AttributeError:
                # Fallback para versÃµes mais antigas
                docs = retriever.get_relevant_documents(pergunta)
            
            if not docs:
                return "âŒ Nenhum documento relevante encontrado para sua pergunta. Tente reformular ou verificar se hÃ¡ documentos na pasta."
            
            # Se tiver mais de uma opÃ§Ã£o relevante e auto_clarify estiver ativo
            if len(docs) > 1 and auto_clarify:
                print(f"\nğŸ“š Encontrei {len(docs)} documentos relevantes")
                doc_escolhido = self.escolher_documento_opcoes(docs, pergunta)
            else:
                doc_escolhido = docs[0]
            
            # Preparar contexto para o LLM
            contexto = doc_escolhido.page_content
            arquivo = doc_escolhido.metadata.get("arquivo", "Desconhecido")
            
            # Prompt melhorado para o LLM com contexto da pergunta
            prompt_template = PromptTemplate(
                input_variables=["context", "question"],
                template="""VocÃª Ã© um assistente especializado em documentos que ajuda usuÃ¡rios a entender o conteÃºdo de documentos.

ğŸ“‹ **ConteÃºdo do documento:**
{context}

â“ **Pergunta do usuÃ¡rio:** {question}

ğŸ’¡ **InstruÃ§Ãµes:**
Baseado APENAS no contexto fornecido, responda Ã  pergunta do usuÃ¡rio de forma clara e precisa.
- Se a informaÃ§Ã£o estiver disponÃ­vel no contexto, forneÃ§a uma resposta completa
- Se a informaÃ§Ã£o NÃƒO estiver disponÃ­vel no contexto, indique claramente isso
- Seja profissional, objetivo e direto ao ponto
- Use o contexto especÃ­fico do documento para fundamentar sua resposta

ğŸ” **Resposta baseada no documento:**"""
            )
            
            # Executar a consulta
            qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=retriever,
                chain_type_kwargs={"prompt": prompt_template}
            )
            
            resposta = qa_chain.invoke({"query": pergunta})
            
            return f"ğŸ“„ **Documento consultado:** {arquivo}\n\n{resposta['result']}"
            
        except Exception as e:
            error_msg = f"âŒ Erro ao executar consulta RAG: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def buscar_documentos_similares(self, texto: str, max_results: int = 3) -> List[Document]:
        """Busca documentos similares a um texto especÃ­fico"""
        try:
            vectorstore = self.carregar_indice()
            if not vectorstore:
                return []
            
            retriever = vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": max_results}
            )
            
            # Usar o mÃ©todo correto baseado na versÃ£o
            try:
                return retriever.invoke(texto)
            except AttributeError:
                # Fallback para versÃµes mais antigas
                return retriever.get_relevant_documents(texto)
            
        except Exception as e:
            logger.error(f"Erro ao buscar documentos similares: {str(e)}")
            return []
    
    def obter_estatisticas_indice(self) -> Dict[str, Any]:
        """Retorna estatÃ­sticas detalhadas sobre o Ã­ndice atual"""
        try:
            vectorstore = self.carregar_indice()
            if not vectorstore:
                return {"status": "erro", "mensagem": "Ãndice nÃ£o disponÃ­vel"}
            
            # Contar documentos
            num_docs = len(vectorstore.docstore._dict)
            
            # Obter tipos de arquivos Ãºnicos
            tipos_arquivo = set()
            arquivos = set()
            total_chunks = 0
            
            for doc_id, doc in vectorstore.docstore._dict.items():
                if hasattr(doc, 'metadata'):
                    tipos_arquivo.add(doc.metadata.get('tipo_arquivo', 'desconhecido'))
                    arquivos.add(doc.metadata.get('arquivo', 'desconhecido'))
                    total_chunks += 1
            
            return {
                "status": "ativo",
                "total_documentos": total_chunks,
                "arquivos_unicos": len(arquivos),
                "tipos_arquivo": list(tipos_arquivo),
                "caminho_indice": INDEX_PATH,
                "ultima_atualizacao": "Agora"
            }
            
        except Exception as e:
            return {"status": "erro", "mensagem": str(e)}
    
    def forcar_recriacao_indice(self) -> bool:
        """ForÃ§a a recriaÃ§Ã£o do Ã­ndice FAISS"""
        try:
            # Remover arquivos existentes
            index_faiss = os.path.join(INDEX_PATH, "index.faiss")
            index_pkl = os.path.join(INDEX_PATH, "index.pkl")
            
            if os.path.exists(index_faiss):
                os.remove(index_faiss)
            if os.path.exists(index_pkl):
                os.remove(index_pkl)
            
            logger.info("Arquivos de Ã­ndice removidos, recriando...")
            return self.criar_indice_faiss()
            
        except Exception as e:
            logger.error(f"Erro ao forÃ§ar recriaÃ§Ã£o do Ã­ndice: {str(e)}")
            return False

# FunÃ§Ãµes de compatibilidade para uso externo
def extrair_documentos_por_ocr(pasta_docs: str) -> list[Document]:
    """FunÃ§Ã£o de compatibilidade para uso externo"""
    processor = DocumentProcessor()
    return processor.extrair_documentos_por_ocr(pasta_docs)

def escolher_documento_opcoes(opcoes: list[Document]) -> Document:
    """FunÃ§Ã£o de compatibilidade para uso externo"""
    processor = DocumentProcessor()
    return processor.escolher_documento_opcoes(opcoes, "Consulta")

def criar_indice_faiss(embeddings):
    """FunÃ§Ã£o de compatibilidade para uso externo"""
    processor = DocumentProcessor()
    return processor.criar_indice_faiss()

def executar_rag(pergunta: str) -> str:
    """FunÃ§Ã£o de compatibilidade para uso externo"""
    processor = DocumentProcessor()
    return processor.executar_rag(pergunta)

if __name__ == "__main__":
    # Teste do sistema
    print("ğŸ§ª Teste do Sistema RAG")
    print("=" * 40)
    
    processor = DocumentProcessor()
    
    # Verificar estatÃ­sticas
    stats = processor.obter_estatisticas_indice()
    print(f"ğŸ“Š EstatÃ­sticas do Ã­ndice: {stats}")
    
    # Teste de consulta
    if stats["status"] == "ativo":
        pergunta = input("\nğŸ” Digite uma pergunta para testar: ")
        if pergunta.strip():
            resposta = processor.executar_rag(pergunta)
            print(f"\nğŸ¤– Resposta: {resposta}")
    else:
        print(f"âŒ Erro no Ã­ndice: {stats['mensagem']}")
        print("ğŸ”„ Tentando criar Ã­ndice...")
        if processor.criar_indice_faiss():
            print("âœ… Ãndice criado com sucesso!")
        else:
            print("âŒ Falha ao criar Ã­ndice")
